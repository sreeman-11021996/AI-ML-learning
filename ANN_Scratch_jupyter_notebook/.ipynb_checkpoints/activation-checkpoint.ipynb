{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8CP1zmfogMPs"
   },
   "outputs": [],
   "source": [
    "from abc import ABC,abstractmethod\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g7TB55Bqg_X4"
   },
   "outputs": [],
   "source": [
    "class Activation(ABC):\n",
    "    # methods required in activation\n",
    "    @abstractmethod\n",
    "    def __call__(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        ...\n",
    "  \n",
    "    @abstractmethod\n",
    "    def gradients(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "snL0VmCHhyO_"
   },
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "\n",
    "    # simoid(x) = 1/(1+e^(-x))\n",
    "    def __call__(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        return 1/(1 + np.exp(-1*input_tensor))\n",
    "  \n",
    "    # d/dx(sigmoid(x)) = (sigmoid(x))*(1 - sigmoid(x))\n",
    "    def gradients(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        return self(input_tensor)*(1 - self(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BWpUW6ulbqV5"
   },
   "outputs": [],
   "source": [
    "class Relu(Activation):\n",
    "\n",
    "    # Relu(x) = max(x,0)\n",
    "    def __call_(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        return np.maximum(input_tensor,0)\n",
    "\n",
    "    # d/dx(Relu(x)) = (0, if x < 0) || (1, if x >= 0)\n",
    "    def gradients(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        result = input_tensor.copy()\n",
    "        result[input_tensor >= 0] = 1\n",
    "        result[input_tensor < 0] = 0\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "01a1-bpOdgq4"
   },
   "outputs": [],
   "source": [
    "class Linear(Activation):\n",
    "\n",
    "    # Linear(x) = x\n",
    "    def __call_(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        return input_tensor\n",
    "\n",
    "    # d/dx(Linear(x)) = 1\n",
    "    def gradients(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        return np.ones(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fO2rGpF3eEh9"
   },
   "outputs": [],
   "source": [
    "class Softmax(Activation):\n",
    "  \n",
    "    def __call__(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        ...\n",
    "  \n",
    "    def gradients(self,input_tensor:np.ndarray)->np.ndarray:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCn6j3n-eyzN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
